{
  "Converte arquivo.txt (Largura Fixa) to csv": {
    "prefix": "#Funcoes",
    "body": [
      "pd.read_fwf(r'arquivo.txt').to_csv(r'arquivo.csv', sep=\";\", encoding=\"iso-8859-1\", decimal=\",\", float_format='%.2f', date_format='%d/%m/%Y', index=False)"
    ]
  },
  "NUMANOMES (mes anterior)": {
    "prefix": "#Funcoes",
    "body": [
      "from dateutil.relativedelta import relativedelta",
      "MESATU_fim = int((pd.to_datetime(\"today\") + relativedelta(months=-1)).strftime(\"%Y%m\")) #Mes Anterior"
    ]
  },
  "Filter_Like": {
    "prefix": "#Funcoes",
    "body": [
      "df[df['RAZAO_SOCIAL'].str.contains(\"MAGAZINE LUIZA\")]"
    ]
  },
  "Filter_NaN": {
    "prefix": "#Funcoes",
    "body": [
      "df[df['DIVNGC'].isnull()]"
    ]
  },
  "Filtrar NaN": {
    "prefix": "#Funcoes",
    "body": [
      "df.query('DESDIVFRN.isnull()')"
    ]
  },
  "SQL": {
    "prefix": "#Funcoes",
    "body": [
      "import pandas as pd",
      "import sys",
      "sys.path.insert(0, r'C:\\oracle\\dwh')",
      "from OracleDWH import conn",
      "pd.options.display.float_format = '{:,.2f}'.format",
      "",
      "mysql = (\"\"\"     ",
      "select * from DWH.RLCOMRCMPOCDOPE FETCH FIRST 5 ROWS ONLY",
      "  \"\"\")",
      "df = pd.read_sql(mysql, con=conn)",
      "conn.close()"
    ]
  },
  "Sort_values": {
    "prefix": "#Funcoes",
    "body": [
      "df.sort_values(by='VLRFAT', ascending=False)"
    ]
  },
  "agate": {
    "prefix": "#Funcoes",
    "body": [
      "arquivo = r'..\\file.xlsx'",
      "column_arquivo = ['DESDRTCLLATU', 'DESCLLCMPATU', 'CODDIVFRN', 'CODUNDREG', 'CODESTCLI', 'POP']",
      "data_type =      ['string',       'string',       'int32',     'int32',     'string',    'float']",
      "table = agate.Table.from_xlsx(arquivo, sheet='Plan1').select(column_arquivo)",
      "df = pd.DataFrame(table)",
      "df = pd.DataFrame(table.rows, columns=table.column_names)",
      "dic_dtype = dict(zip(column_arquivo, data_type))",
      "df = df.astype(dtype=dic_dtype)"
    ]
  },
  "concat; union all": {
    "prefix": "#Funcoes",
    "body": [
      "df_full = pd.concat([omrcmp, df_full])"
    ]
  },
  "count distinct (mais de uma coluna)": {
    "prefix": "#Funcoes",
    "body": [
      "(df['CODGRPPRD'].astype(str)+df['CODCTGPRD'].astype(str)).nunique()"
    ]
  },
  "eval (coluna calculada)": {
    "prefix": "#Funcoes",
    "body": [
      "df_full.eval('VLRMRGCRB=VLRMRGBRT+VLRCSTMC', inplace=True)"
    ]
  },
  "drop columns; erase; del; Excluir Colunas": {
    "prefix": "#Funcoes",
    "body": [
      "df.drop(columns=['VLRMRGCRB'], inplace=True)"
    ]
  },
  "float_format": {
    "prefix": "#Funcoes",
    "body": [
      "pd.options.display.float_format = '{:,.2f}'.format"
    ]
  },
  "left join where right is null": {
    "prefix": "#Funcoes",
    "body": [
      "dfdif = pd.merge(df, dfsql[['NUMANOMESDIA', 'NUMNOTFSC', 'NUM_ORDEM', 'CODPRD']],  indicator='i', how='outer', on=['NUMANOMESDIA', 'NUMNOTFSC', 'NUM_ORDEM', 'CODPRD']).query('i == \"left_only\"').drop('i', 1)"
    ]
  },
  "listar as colunas dataset": {
    "prefix": "#Funcoes",
    "body": [
      "list(df.columns)"
    ]
  },
  "listar registros unicos (colocar entre parenteses)": {
    "prefix": "#Funcoes",
    "body": [
      "tuple(df['DESTIPCNLVNDOMR'].unique())"
    ]
  },
  "max (maior string de um campo)": {
    "prefix": "#Funcoes",
    "body": [
      "len(max(df['DESCTGPRD'], key=len))"
    ]
  },
  "melt (Transpor de colunas pra linhas)": {
    "prefix": "#Funcoes",
    "body": [
      "df = pd.melt(df, id_vars=['Produto'], #variaveis continuam nas colunas",
      "  value_vars=['Fat','MB'], #colunas transpostas para linhas",
      "  var_name='Medida', #nome da nova coluna",
      "  value_name='Valor') #valor das colunas transpostas"
    ]
  },
  "pivot (Transpor de linhas para colunas sem agrupar)": {
    "prefix": "#Funcoes",
    "body": [
      "df.pivot(index=['DESDRTCLLATU', 'DESCTGPRD'], columns=['NOMMES'], values='VLRVNDFATLIQ')"
    ]
  },
  "pivot_table (Transpor de linhas para colunas)": {
    "prefix": "#Funcoes",
    "body": [
      "pd.pivot_table(df_full, values='DRIVER', index=['DESDRTCLLATU', 'DESCTGPRD', 'DESDIVFRN'],  columns=['MEDIDA'], aggfunc=sum)"
    ]
  },
  "query isin": {
    "prefix": "#Funcoes",
    "body": [
      "dftrf = df.query('CODDIVFRN in [95010,95036,95014,97608,96953,97605]')"
    ]
  },
  "read_csv": {
    "prefix": "#Funcoes",
    "body": [
      "df = pd.read_csv(r'..\\OMR 2022.csv', ';', encoding=\"iso-8859-1\", decimal=',')"
    ]
  },
  "read_excel": {
    "prefix": "#Funcoes",
    "body": [
      "df = pd.read_excel(r'..\\Plan_Operacional Diretorias CARGA.xlsx', 'VAREJO', skiprows = 6, nrows= 5, usecols = \"B:C,M:N,Q:R\")"
    ]
  },
  "read_pickle": {
    "prefix": "#Funcoes",
    "body": [
      "pd.read_pickle(r'..\\OMR_COMPRAS_POP.pkl')"
    ]
  },
  "rename columns": {
    "prefix": "#Funcoes",
    "body": [
      "ocdcmpmes.rename(columns={'CODDIVFRN':'CODFRN', 'MES':'NOMMES'}, inplace=True)"
    ]
  },
  "replace": {
    "prefix": "#Funcoes",
    "body": [
      "df['DESTIPCNLVNDOMR'].replace('E-F\u00c1CIL', 'EFACIL', inplace=True)"
    ]
  },
  "sort_values": {
    "prefix": "#Funcoes",
    "body": [
      ".sort_values(by='TIPCNL')"
    ]
  },
  "string slice (cortar parte texto)": {
    "prefix": "#Funcoes",
    "body": [
      "df['DESTIPCNLVNDOMR'].str.slice(7,13)",
      "df['A'].str[:255]"
    ]
  },
  "to_csv": {
    "prefix": "#Funcoes",
    "body": [
      "df.to_csv(r'..\\CTGPRD.csv', sep=\";\", encoding=\"iso-8859-1\", decimal=\",\", float_format='%.2f', date_format='%d/%m/%Y', index=False)"
    ]
  },
  "to_pickle": {
    "prefix": "#Funcoes",
    "body": [
      "df.to_pickle('Export.pkl')"
    ]
  },
  "to_string": {
    "prefix": "#Funcoes",
    "body": [
      "print(df.to_string(float_format='%.2f', decimal=',', index=None))"
    ]
  },
  "unique (select distinct)": {
    "prefix": "#Funcoes",
    "body": [
      "df.drop_duplicates(['CODUNDNGCCLI','DESUNDNGCCLI'])[['CODUNDNGCCLI','DESUNDNGCCLI']]",
      "df.loc[~df.CODDIVFRN.isin([95010,95036,95014,97608,96953,97605]) & df.CODFILEPD.isin([64]), ['CODFILEPD', 'DESCTGPRD']].drop_duplicates(['CODFILEPD', 'DESCTGPRD'])"
    ]
  },
  "unique key (codigo e descricao mais recorrente)": {
    "prefix": "#Funcoes",
    "body": [
      "#Garantir unique key dos codigos e pegar a descricao que tem mais quantidade de registros",
      "drt = dim_compras[['CODDRTCLLATU', 'DESDRTCLLATU']].value_counts().reset_index().iloc[:,:-1]",
      "drt.drop_duplicates(['CODDRTCLLATU'], keep='first', inplace=True)"
    ]
  },
  "unique key (duplicated = False)": {
    "prefix": "#Funcoes",
    "body": [
      "df[['CODGRPPRD', 'CODCTGPRD', 'CODDIVFRN', 'DESDIVFRN', 'CODFILEPD']].duplicated().any()"
    ]
  },
  "Estrutura Tabelas (MRT DWH)": {
    "prefix": "#Funcoes",
    "body": [
      "#Parametros da Consulta",
      "table = 'T0311452'",
      "owner = 'MRT'",
      "",
      "#importa\u00e7\u00e3o das bibliotecas python",
      "import pandas as pd",
      "import numpy as np",
      "import sys",
      "sys.path.insert(0, r'C:\\oracle\\dwh')",
      "from OracleDWH_tscdsc import conn",
      "pd.options.display.float_format = '{:,.2f}'.format",
      "",
      "#SQL",
      "sql=(\"\"\" ",
      "SELECT A.COLUMN_NAME, A.COMMENTS, B.DATA_TYPE, B.DATA_LENGTH, B.COLUMN_ID",
      "FROM ALL_COL_COMMENTS A inner join all_tab_columns B ON A.OWNER = B.OWNER AND A.TABLE_NAME = B.TABLE_NAME AND A.COLUMN_NAME = B.COLUMN_NAME",
      "WHERE A.TABLE_NAME = %s",
      "AND A.OWNER = %s",
      "ORDER BY B.COLUMN_ID",
      "\"\"\")",
      "#Formata parametros",
      "filen = owner + '.' + table + '.csv'",
      "table = \"'\" + table + \"'\"",
      "owner = \"'\" + owner + \"'\"",
      "",
      "my_sql_query=(sql % (table, owner))",
      "",
      "#Executa e printscreen",
      "print(pd.read_sql(my_sql_query, con=conn).to_string())",
      "conn.close()"
    ]
  },
  "criptografar": {
    "prefix": "#Funcoes",
    "body": [
      "import base64",
      "code = base64.b64encode(bytes('senha', 'utf-8'))",
      "print(code)"
    ]
  },
  "send_mail": {
    "prefix": "#Funcoes",
    "body": [
      "import sys",
      "sys.path.insert(0, r'C:\\oracle\\dwh')",
      "from email.mime.text import MIMEText",
      "from email.mime.multipart import MIMEMultipart",
      "from email.mime.base import MIMEBase",
      "from pretty_html_table import build_table",
      "from envia_mail import server",
      "from email import encoders",
      "",
      "address_book = ['elton.mata@martins.com.br']",
      "sender = 'elton.mata@martins.com.br'",
      "subject = \"Infla\u00e7\u00e3o Interna\"",
      "tabela = build_table(df_full, 'blue_light', text_align='right')",
      "",
      "body = f\"\"\"<html><body><p>Infla\u00e7\u00e3o Interna acumulada 12 meses</p>",
      "{tabela}",
      "</body></html>",
      "\"\"\"",
      "#anexar arquivo",
      "file = \"InflacaoInterna_Mensal.csv\"",
      "attachment = open(file,'rb')",
      "obj = MIMEBase('application','octet-stream')",
      "obj.set_payload((attachment).read())",
      "encoders.encode_base64(obj)",
      "obj.add_header('Content-Disposition',\"attachment; filename= \"+file)",
      "",
      "msg = MIMEMultipart()",
      "msg['From'] = sender",
      "msg['To'] = ','.join(address_book)",
      "msg['Subject'] = subject",
      "msg.attach(MIMEText(body, 'html'))",
      "msg.attach(obj)",
      "text=msg.as_string()",
      "server.sendmail(sender,address_book, text)",
      "server.quit()"
    ]
  },
  "rename index to None": {
    "prefix": "#Funcoes",
    "body": [
      "df.index.name = None"
    ]
  },
  "rename column to None": {
    "prefix": "#Funcoes",
    "body": [
      "df.columns.name = None",
      ".rename_axis(None, axis=1)"
    ]
  },
  "confere": {
    "prefix": "Summary",
    "body": [
      "print('CANAL ATUAL')",
      "pd.options.display.float_format = '{:,.2f}'.format",
      "confere1 = df.groupby('CODCNLVND')[['VLRVNDFATLIQ', 'VLRRCTLIQAPU', 'VLRMRGBRT', 'VLRMRGCRB']].sum()",
      "confere1.loc['TOTAL'] = confere1.sum()",
      "print(confere1.to_string())",
      "print('CANAL AJUSTADO')",
      "pd.options.display.float_format = '{:,.2f}'.format",
      "confere2 = df.groupby('CODCNLVND')[['VLRVNDFATLIQ', 'VLRRCTLIQAPU', 'VLRMRGBRT', 'VLRMRGCRB']].sum()",
      "confere2.loc['TOTAL'] = confere2.sum()",
      "print(confere2.to_string(), '\\n')",
      "print('DIREFEREN\u00c7A (ATUAL - AJUSTADO)')",
      "print(confere1-confere2)"
    ]
  },
  "dict (inverter key item)": {
    "prefix": "#Funcoes",
    "body": [
      "dicio = {x: y for y, x in dicio.items()}"
    ]
  },
  "enumarate (DePara nommes)": {
    "prefix": "#Funcoes",
    "body": [
      "DePara = enumerate(['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'], start=1)",
      "DePara = dict(DePara)",
      "DePara_inverso = {x: y for y, x in DePara.items()}"
    ]
  },
  "set_index": {
    "prefix": "#Funcoes",
    "body": [
      "df=df.set_index('NUMANOMESDIA')"
    ]
  },
  "NUMANOMES (Acumulado ate Mes Anterior)": {
    "prefix": "#Funcoes",
    "body": [
      "from dateutil.relativedelta import relativedelta",
      "#FLGMESATU = 1 #(Acumulado ate mes atual)",
      "FLGMESATU = 0 #(Acumulado ate mes anterior)",
      "pNUMANOMESINI = int((pd.to_datetime(\"today\") + relativedelta(months=-1+FLGMESATU)).strftime(\"%Y\"))*100+1 #Mes de Jan do Ano atual",
      "pNUMANOMESFIM = int((pd.to_datetime(\"today\") + relativedelta(months=-1+FLGMESATU)).strftime(\"%Y%m\")) #Mes Anterior",
      "pNUMANOMESINIa = int((pd.to_datetime(\"today\") + relativedelta(months=-13+FLGMESATU)).strftime(\"%Y\"))*100+1 #Mes de Jan Ano anterior",
      "pNUMANOMESFIMa = int((pd.to_datetime(\"today\") + relativedelta(months=-13+FLGMESATU)).strftime(\"%Y%m\")) #Mes Anterior do Ano Anterior"
    ]
  },
  "NUMANOMES (Mes anterior ate dia 15 ou atual apos)": {
    "prefix": "#Funcoes",
    "body": [
      "#MesAnterior (ate dia 15); MesAtual apos",
      "if int(pd.to_datetime(\"today\").strftime(\"%d\")) < 15:",
      "    ANOMES = int((pd.to_datetime(\"today\") + relativedelta(months=-1)).strftime(\"%Y%m\")) #Mes Anterior",
      "else:",
      "    ANOMES = int((pd.to_datetime(\"today\") + relativedelta(months=0)).strftime(\"%Y%m\")) #Mes Atual"
    ]
  },
  "NUMANOMES (Ultimas 8 semanas)": {
    "prefix": "#Funcoes",
    "body": [
      "from datetime import datetime, timedelta",
      "",
      "domingo = datetime.now() - timedelta(days = datetime.now().weekday()+1) #Ultimo Domingo",
      "#segunda = datetime.now() - timedelta(days = datetime.now().weekday()+ (7*1)) #Segunda Semana anterior",
      "segunda = datetime.now() - timedelta(days = datetime.now().weekday()+ (7*8) ) #Segunda de 8 semanas atras",
      "print('segunda de 8 semanas atras:', segunda)",
      "print('ultimo domingo:', domingo)",
      "",
      "ANOMESDIAini = int(segunda.strftime(\"%Y%m%d\"))",
      "ANOMESDIAfim = int(domingo.strftime(\"%Y%m%d\"))",
      "print('Periodo (Ultimas 8 semanas):', ANOMESDIAini, \"-\", ANOMESDIAfim)",
      ""
    ]
  },
  "Create DataFrame": {
    "prefix": "#Funcoes",
    "body": [
      "df = pd.DataFrame({'Coluna1':['A'], 'Coluna2':[1.0]})"
    ]
  },
  "SQLite (read_sql to_sql)": {
    "prefix": "#Funcoes",
    "body": [
      "import pandas as pd",
      "import sys",
      "sys.path.insert(0, r'C:\\oracle\\dwh')",
      "from OracleDWH import conn",
      "import sqlite3",
      "conn_sqlite = sqlite3.connect('file.db')",
      "",
      "my_sql_query = (\"\"\"",
      "SELECT * from dwh.RLCOMRCMPOCDOPE",
      "\t\t\"\"\")",
      "pd.read_sql(my_sql_query, con=conn).to_sql('rlcomrcmpocdope', conn_sqlite, if_exists='replace', index=False, chunksize=10000)",
      "",
      "conn.close()",
      "conn_sqlite.close()"
    ]
  },
  "Formatar decimal comma ,": {
    "prefix": "#Funcoes",
    "body": [
      "def formatnumbers(x):",
      "#    x = round(x, 2)",
      "    x = str(x).replace('.', ',')",
      "    return x",
      "    ",
      "for col in df.columns:",
      "    df[col] =  df[col].apply(formatnumbers)"
    ]
  },
  "send_email (texto sem anexos)": {
    "prefix": "#Funcoes",
    "body": [
      "#Envia apenas texto",
      "import sys",
      "sys.path.insert(0, r'C:\\oracle\\dwh')",
      "from email.mime.text import MIMEText",
      "from email.mime.multipart import MIMEMultipart",
      "from envia_mail import server",
      "",
      "address_book = ['elton.mata@martins.com.br']",
      "address_bookCC = ['elton.mata@martins.com.br']",
      "sender = 'elton.mata@martins.com.br'",
      "subject = \"Execu\u00e7\u00e3o eventual -- WADWH31B\"",
      "",
      "body = f\"\"\"<html><body>",
      "<p>Solicito a execu\u00e7\u00e3o eventual do grupo WADWH31B que est\u00e1 na aplica\u00e7\u00e3o E_WA</p>",
      "<p>Par\u00e2metro a ser informado <b>ANO = 2022</b></p>",
      "",
      "<p>",
      "    Att, Elton<br />",
      "    Planejamento, Controle e Gest\u00e3o<br />",
      "    Ramal 1246",
      "</p>",
      "",
      "</body></html>",
      "\"\"\"",
      "",
      "msg = MIMEMultipart()",
      "msg['From'] = sender",
      "msg['To'] = ','.join(address_book)",
      "msg['Cc'] = ','.join(address_bookCC)",
      "msg['Subject'] = subject",
      "msg.attach(MIMEText(body, 'html'))",
      "text=msg.as_string()",
      "server.sendmail(sender,address_book, text)",
      "server.quit()"
    ]
  },
  "NUMANOMES (mes anterior from datetime)": {
    "prefix": "#Funcoes",
    "body": [
      "from datetime import date",
      "from dateutil.relativedelta import relativedelta",
      "",
      "mesref = int((date.today() + relativedelta(months=-1)).strftime(\"%Y%m\")) #Mes Anterior"
    ]
  },
  "Tempo_Execu\u00e7\u00e3o": {
    "prefix": "#Funcoes",
    "body": [
      "import time",
      "start = time.strftime(\"%b %d %Y %H:%M:%S\")",
      "print(start, '--', time.strftime(\"%H:%M:%S\"))"
    ]
  },
  "reset_index (erro feather serializing)": {
    "prefix": "#Funcoes",
    "body": [
      "df.reset_index(drop=True, inplace=True)"
    ]
  },
  "Definir valor fixo em uma coluna (set value)": {
    "prefix": "#Funcoes",
    "body": [
      "df.loc[df.RL_POP == 0,'PERMB'] = 0.23"
    ]
  },
  "NUMANOMESDIA (ultimo dia do mes)": {
    "prefix": "NUMANOMESDIA (ultimo dia do mes)",
    "body": [
      "import datetime ",
      "from dateutil.relativedelta import relativedelta",
      "",
      "ano = 2021",
      "meses = list(range(1, 13, 1))",
      "NUMANOMESDIA = [(datetime.datetime(2021, x, 1) + relativedelta(day=31)).strftime(\"%Y%m%d\") for x in meses]"
    ]
  },
  "pivot_table (com linha de total)": {
    "prefix": "#Funcoes",
    "body": [
      "dfpvt = pd.pivot_table(df, values='VLRFATLIQ', index=['CANALVENDAS'],  columns=['NUMANOMES'], aggfunc=sum)",
      "dfpvt.loc['TOTAL'] = dfpvt.sum(axis=0)",
      "dfpvt = dfpvt.reset_index()"
    ]
  },
  "define o nome das colunas como string (para nao dar erro no export excel com xlsxwriter)": {
    "prefix": "#Funcoes",
    "body": [
      "data = list(dfpvt.columns)",
      "data = [''+ str(x) for x in data]",
      "df.columns = data"
    ]
  },
  "Export Excel (Formato Tabela xlsxwriter)": {
    "prefix": "#Funcoes",
    "body": [
      "writer = pd.ExcelWriter('arquivo.xlsx', engine='xlsxwriter')",
      "df.to_excel(writer, sheet_name='CANALVENDAS', startrow=1, header=False, index=False)",
      "workbook = writer.book",
      "format1 = workbook.add_format({'num_format': '#,##0.00'})",
      "worksheet = writer.sheets['CANALVENDAS']",
      "(max_row, max_col) = df.shape",
      "column_settings = [{'header': column} for column in df.columns]",
      "worksheet.add_table(0, 0, max_row, max_col - 1, {'columns': column_settings})",
      "worksheet.set_column(0, 0, 40) #Posi\u00e7\u00e3o coluna inicial, posi\u00e7\u00e3o coluna final, largura coluna",
      "worksheet.set_column(1, max_col - 1, 15) #15 = largura da coluna",
      "worksheet.set_column(1, max_col - 1, 15, format1)",
      "writer.save()"
    ]
  },
  "create folder": {
    "prefix": "#Funcoes",
    "body": [
      "import os",
      "if not os.path.exists(caminho + '/bd'):",
      "    os.makedirs(caminho + '/bd')"
    ]
  },
  "concatenar codigo.descricao": {
    "prefix": "#Funcoes",
    "body": [
      "df['PACOTE'] = list((''.join([x.zfill(3), '.', y])) for x, y in zip(df['CODPCTOCD'].astype(str),df['DESPCTOCD']))"
    ]
  },
  "Rename Columns in groupby with add_prefix": {
    "prefix": "#Funcoes",
    "body": [
      "df.groupby('DAY')[['TTM','TTS']].mean().add_prefix('mean')"
    ]
  },
  "Multiplicar colunas no groupby - assign": {
    "prefix": "#Funcoes",
    "body": [
      "df.assign(TOTAL=df.eval('QDEITE * PRECO')).groupby(['NUMANOMES'])[['TOTAL']].sum()"
    ]
  },
  "NUMANO from NUMANOMES (substr)": {
    "prefix": "#Funcoes",
    "body": [
      "df['ANO'] = df['NUMANOMES'].astype('str').str[:4]"
    ]
  },
  "SQL (SQLAlchemy)": {
    "prefix": "#Funcoes",
    "body": [
      "import pandas as pd",
      "from sqlalchemy import create_engine, Table, MetaData, select, func",
      "engine = create_engine('oracle+cx_oracle://user:senha@dwh01', echo=False)",
      "pd.options.display.float_format = '{:,.2f}'.format",
      "",
      "FTOOMR = Table('ftoocdmtzrctcmp', MetaData(), autoload_with=engine, schema='dwh')",
      "DIMPOD = Table('dimpod', MetaData(), autoload_with=engine, schema='dwh')",
      "DIMTIP = Table('dimtip', MetaData(), autoload_with=engine, schema='dwh')",
      "DIMCNO = Table('dimcnoocd', MetaData(), autoload_with=engine, schema='dwh')",
      "DIMFIL = Table('dimfil', MetaData(), autoload_with=engine, schema='dwh')",
      "",
      "qry = select(DIMPOD.c.numanomes",
      "              , DIMFIL.c.codfil",
      "              , DIMFIL.c.desfil",
      "              , func.sum(FTOOMR.c.vlrvndfatliq).label(\"VLRVNDFATLIQ\")",
      "              , func.sum(FTOOMR.c.vlrrctliqapu).label(\"VLRRCTLIQAPU\")",
      "              , func.sum(FTOOMR.c.vlrmrgbrt).label(\"VLRMRGBRT\")",
      "              , func.sum(FTOOMR.c.vlrmrgcrb).label(\"VLRMRGCRB\"))\\",
      "          .join(DIMPOD, FTOOMR.c.srkpodref == DIMPOD.c.srkpod)\\",
      "          .join(DIMTIP, FTOOMR.c.srktipopevnd == DIMTIP.c.srktip)\\",
      "          .join(DIMCNO, FTOOMR.c.srkcnoocd == DIMCNO.c.srkcnoocd)\\",
      "          .join(DIMFIL, FTOOMR.c.srkfil == DIMFIL.c.srkfil)\\",
      "          .filter((DIMPOD.c.numanomes == 202202) ",
      "                & (DIMTIP.c.codtip == 'FAT') ",
      "                & (DIMCNO.c.codcnoocd == 'POP'))\\",
      "          .group_by(DIMPOD.c.numanomes, DIMFIL.c.codfil, DIMFIL.c.desfil)",
      "df = pd.read_sql_query(qry, engine)"
    ]
  },
  "Groupby without index (as_index=False)": {
    "prefix": "Groupby without index (as_index=False)",
    "body": [
      "df.groupby('col1', as_index=False).nunique()"
    ]
  },
  "count distinct -- unique (coluna dataframe)": {
    "prefix": "#Funcoes",
    "body": [
      "list(map(tuple, df.groupby('col1', as_index=False).nunique().values))"
    ]
  },
  "Rateio": {
    "prefix": "#Funcoes",
    "body": [
      "df['PARTIC_PESOCUB'] = (df['PESO_ENTREGA'] / df.groupby(['CODFILLGT','CODCID'])['PESO_ENTREGA'].transform('sum'))"
    ]
  },
  "Substituir Negativos por Zero": {
    "prefix": "Substituir Negativos por Zero",
    "body": [
      "df['col']=df['col'].apply(lambda x : 0 if x<0 else x)"
    ]
  },
  "Converter nome colunas maiusculas (uppercase)": {
    "prefix": "#Funcoes",
    "body": [
      "df.columns = list(df.columns.str.upper())"
    ]
  },
  "Conferir_Total_(Transpose)": {
    "prefix": "#Funcoes",
    "body": [
      "print(pd.DataFrame(df[['VLRTOTVNDPPS',  'VLRPPSMRGCRBVND', 'VLRRCTLIQAPUOCD',  'VLRMRGBRTOCD']].sum()).transpose().to_markdown(tablefmt='github', floatfmt=',.2f', index=False),'\\n')"
    ]
  },
  "Conferir_Total_(Rename Column)": {
    "prefix": "#Funcoes",
    "body": [
      "print(infodia.agg({'VLRTOTFAT':'sum', 'VLRPRVFAT': 'sum'}).rename({'VLRTOTFAT':'FAT_RLZ', 'VLRPRVFAT': 'FAT_POP'}))"
    ]
  },
  "Filter item dicionario": {
    "prefix": "Filter item dicionario",
    "body": [
      "Dicionario.get('Item_key')"
    ]
  },
  "Excluir Nulos (Drop NaN)": {
    "prefix": "#Funcoes",
    "body": [
      "df = df.dropna()"
    ]
  },
  "Eliminar Linhas NaN (dropna)": {
    "prefix": "Eliminar Linhas NaN (dropna)",
    "body": [
      "df.dropna(inplace=True)"
    ]
  },
  "Cross Join": {
    "prefix": "#Funcoes",
    "body": [
      "dfdif = pd.merge(dfdif, sazao_total, how='cross')"
    ]
  },
  "Filter by value_counts": {
    "prefix": "#Funcoes",
    "body": [
      "df = df[df['NOMPLO'].isin(df['NOMPLO'].value_counts()[df['NOMPLO'].value_counts()==12].index)]"
    ]
  },
  "File or Folder exist": {
    "prefix": "#Functions",
    "body": [
      "import os",
      "from pathlib2 import Path",
      "",
      "#caminho_file = Path(r\"X:\\PLANEJAMENTO\\2022\\11 Alteracao Estado AP CIF-FOB\\RLCOMRCMPOCDOPE_CARGA.pkl\")",
      "caminho_folder = Path(r\"X:\\PLANEJAMENTO\\2022\\11 Alteracao Estado AP CIF-FOB\")",
      "",
      "if not caminho_folder.exists():",
      "    print('arquivo n\u00e3o existe')",
      "else:",
      "    print('arquivo existe')"
    ]
  },
  "query like": {
    "prefix": "#funcoes",
    "body": [
      "df.query('DESEDEVND.str.contains(\"VENDEDOR CLT\") & CODCNLVND==10')",
      "df.query('DESTIPCNLVNDOMR.str.startswith(\"OUTROS\")')",
      "df.query('DESTIPCNLVNDOMR.str.endswith(\"CANAIS\")')",
      "df.query('DESTIPCNLVNDOMR.str.match(\"OUTROS CANAIS\")')"
    ]
  },
  "query between": {
    "prefix": "#Funcoes",
    "body": [
      "df.query('CODFRN.between(97700,97799)')"
    ]
  },
  "Export Excel (autofit column xslxwriter)": {
    "prefix": "#Funcoes",
    "body": [
      "",
      "def get_col_widths(dataframe):",
      "    # First we find the maximum length of the index column   ",
      "    idx_max = max([len(str(s)) for s in df.index.values] + [len(str(df.index.name))])",
      "    # Then, we concatenate this to the max of the lengths of column name and its values for each column, left to right",
      "    return [idx_max] + [max([len(str(s)) for s in df[col].values] + [len(col)]) for col in df.columns]",
      "",
      "writer = pd.ExcelWriter('O:/Projeto_CustoABC_2018/Modelo SAS/Modelo de Rentabilidade/Dimensoes/Estoque_FornecedorFilialComprador.xlsx', engine='xlsxwriter')",
      "df.to_excel(writer, sheet_name='ESTOQUE', startrow=1, header=False, index=False)",
      "workbook = writer.book",
      "format1 = workbook.add_format({'num_format': '#,##0.00'})",
      "worksheet = writer.sheets['ESTOQUE']",
      "(max_row, max_col) = df.shape",
      "column_settings = [{'header': column} for column in df.columns]",
      "worksheet.add_table(0, 0, max_row, max_col - 1, {'columns': column_settings})",
      "#worksheet.set_column(0, max_col - 1, 15) #15 = largura da coluna",
      "for i, width in enumerate(get_col_widths(df)):",
      "    worksheet.set_column(i-1, i-1, width+4)",
      "worksheet.set_column(max_col - 1, max_col - 1, 15, format1)",
      "writer.save()"
    ]
  }
}